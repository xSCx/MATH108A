\documentclass[12pt]{amsart}

\usepackage[margin=1.25in]{geometry}

\usepackage{comment}

\begin{document}

\begin{center}
{\bf 108A HW 7 }\\
\end{center}
\rightline{Yuchen Wang,Luis Ramirez,Shengbo Zhang}
\textbf{Section 3} \\
\textbf{Exercise 1}\\
(f) -14\\
\\
\textbf{Exercise 5}\\
(a)  
\[ 
D =
\left|\begin{array}{cccc} 
    1 &    x_1    & {x_1}^2 \\ 
    1 &    x_2    & {x_2}^2\\ 
    1 &    x_3    & {x_3}^2 
\end{array}\right| 
=
\left|\begin{array}{cccc}  
    x_2    & {x_2}^2\\ 
    x_3    & {x_3}^2 
\end{array}\right|
-\ x_1
\left|\begin{array}{cccc}  
    1    & {x_2}^2\\ 
    1    & {x_3}^2 
\end{array}\right|
-\ {x_1}^2
\left|\begin{array}{cccc}  
    1    & {x_2}\\ 
    1    & {x_3} 
\end{array}\right|
\]
\[
= x_2 x_3(x_2 -x_3)+{x_1}^2(x_3 - x_2)
\]
\[
=(x_3 - x_2)(x_2 - x_1)(x_3 -x_1)
\]
(b)\\
The result is true when n=2 or n=3 because
\[
\left|\begin{array}{cccc} 
    1 &    x_1   \\ 
    1 &    x_2   \\ 
\end{array}\right| 
= x_2-x_1
\]
\[
V_n=
\left|\begin{array}{cccccc} 
    1& 0&... & 0 & 0 \\ 
    1&(x_2-x_1)&...&x^{(n-3)}(x_2-x_1)&x^{(n-2)}_{2}(x_2-x_1)\\
    1&(x_3-x_1)&...&x^{(n-3)}(x_3-x_1)&x^{(n-2)}_{3}(x_2-x_1)\\ 
    ...&&...&&\\
    1&(x_n-x_1)&...&x^{(n-3)}(x_n-x_1)&x^{(n-2)}_{n}(x_2-x_1)
\end{array}\right| 
\]
\\
\textbf{Exercise 6}\\
(i)\\
\[
Det[A] =
a_{11}
\left|\begin{array}{cccc} 
    a_{22} & a_{23} & ... & a_{2n} \\ 
    0 &  & &...\\
    ... &    &  & a_{{n-1}n}\\ 
    0 & ...  & 0 & a_{nn} 
\end{array}\right| 
\]
Therefore, $Det(A)=a_{11}a_{22}...a_{nn}$.\\
\textbf{Exercise 11}\\
Differentiating $n-1$ times and setting $t = 0$ in each equation, we see that the system
$$ \left\{
\begin{aligned}
x_1 + ... + x_n & = & 0 \\
x_1\alpha_1 + ... +x_n\alpha_n & = & 0 \\
....\\
x_1{\alpha_1^{n - 1}} + ... + x_n{\alpha_n^{n - 1}} = 0\\
\end{aligned}
\right.
$$ 
has a nontrivial solution. So, the column vectors must be linearly dependent and hence the determinant
$$
\left|\begin{array}{cccc} 
    1 &    6    & ... & 1 \\ 
    \alpha_1 &    \alpha_2   &  .... & \alpha_n\\ 
    ... & ... & ... &... \\
    {\alpha_1^{n - 1}} & {\alpha_2^{n - 1}} & ... & {\alpha_n^{n - 1}} 
\end{array}\right| 
$$
must be $0$. But $\alpha_1 ... \alpha_n$ are distinct, we see at once that the Vandermonde determinant is non-zero. We get a contradiction because the determinant of matrix is equal to te determiannt of its transpose.\\
\\
\textbf{Section 4}\\
\textbf{Exercise 1}\\
(a). $x = \frac{-1}{3}, y = \frac{2}{3}, z = \frac{-1}{3}$ \\
\\
\textbf{Section 5}\\
\textbf{Exercise 1}\\
(a)we see that $\tau_{12}(\sigma) = \tau_{23}$. So $\sigma = {\tau_{12}^{-1}}\tau_{23}$, and $\varepsilon(\sigma) = (-1)_2 = 1$  \\
(g)we see that $\tau_{14}(\sigma) = \tau_{34}$. So $\sigma = {\tau_{14}^{-1}}\tau_{34}$, and $\varepsilon(\sigma) = 1$\\
\\
\textbf{Section 8}\\
\textbf{Exercise 2}\\
We seek a contradiction. Suppose A has an inverse.\\
Then, $1=Det(I)=Det(AA^{-1})$\\
By the fact given, $Det(AA^{-1})=Det(A)Det(A^{-1})$\\
But $Det(A)=0$, so $0(Det(A^{-1})\neq1$, which is a contradiction. Thus matrix A does not have an inverse\\
\\
\textbf{Section 9}\\
\textbf{Exercise 2}\\
Rank=2, because row1 and row2 are Linearly Independent since row1+row2=row3\\
\\
\textbf{Exercise 3}\\
Rank=2, because row1 and row2 are Linearly Independent since 2(row1)+row2=row3\\
\end{document}